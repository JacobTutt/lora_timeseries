{
    "learning_rate": 0.001,
    "batch_size": 2.0,
    "no_tokens": 512.0,
    "val_step_tracker": [
        1,
        100
    ],
    "train_step_tracker": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14,
        15,
        16,
        17,
        18,
        19,
        20,
        21,
        22,
        23,
        24,
        25,
        26,
        27,
        28,
        29,
        30,
        31,
        32,
        33,
        34,
        35,
        36,
        37,
        38,
        39,
        40,
        41,
        42,
        43,
        44,
        45,
        46,
        47,
        48,
        49,
        50,
        51,
        52,
        53,
        54,
        55,
        56,
        57,
        58,
        59,
        60,
        61,
        62,
        63,
        64,
        65,
        66,
        67,
        68,
        69,
        70,
        71,
        72,
        73,
        74,
        75,
        76,
        77,
        78,
        79,
        80,
        81,
        82,
        83,
        84,
        85,
        86,
        87,
        88,
        89,
        90,
        91,
        92,
        93,
        94,
        95,
        96,
        97,
        98,
        99,
        100
    ],
    "val_loss_tracker": [
        3.4571556282043456,
        1.7708878016471863
    ],
    "train_loss_tracker": [
        8.94746208190918,
        0.9365929961204529,
        0.9316208362579346,
        0.9224611520767212,
        1.9591009616851807,
        3.8715267181396484,
        1.3543787002563477,
        0.9061894416809082,
        2.266984701156616,
        1.5418455600738525,
        0.8992916941642761,
        0.8934445381164551,
        0.7598676681518555,
        0.7002372741699219,
        1.0211836099624634,
        0.6048927307128906,
        0.8525033593177795,
        0.814805269241333,
        0.6794560551643372,
        0.5555183291435242,
        0.8732005953788757,
        0.9339518547058105,
        0.5672240257263184,
        0.5127614736557007,
        0.26393094658851624,
        0.9216145277023315,
        0.7865791320800781,
        0.7140787243843079,
        0.23528994619846344,
        0.9773588180541992,
        0.717949390411377,
        0.40963155031204224,
        0.7659178376197815,
        0.2151850312948227,
        0.8225542902946472,
        0.8228476643562317,
        0.6837295889854431,
        0.5254958868026733,
        0.621627688407898,
        0.6172915101051331,
        0.3862797021865845,
        0.7974842190742493,
        0.6700491905212402,
        0.657136857509613,
        0.44205743074417114,
        0.6569501757621765,
        0.7702122926712036,
        0.3075491487979889,
        0.18431003391742706,
        0.8195699453353882,
        0.6882032752037048,
        0.8700066804885864,
        0.3511516749858856,
        0.43821579217910767,
        0.6036389470100403,
        0.17319506406784058,
        0.8422417640686035,
        0.420223593711853,
        0.6920418739318848,
        0.4689614772796631,
        0.5670115351676941,
        0.5940398573875427,
        0.3793313503265381,
        0.15980517864227295,
        0.6040492057800293,
        0.7233017086982727,
        0.36351850628852844,
        0.6644842028617859,
        0.4152939021587372,
        0.28815412521362305,
        0.7447189688682556,
        0.36050188541412354,
        0.2376643717288971,
        0.5337211489677429,
        0.5628972053527832,
        0.6056143045425415,
        0.13759303092956543,
        0.5439213514328003,
        0.2209644615650177,
        0.5617964267730713,
        0.5022462606430054,
        0.3408648669719696,
        0.6212397217750549,
        0.38727909326553345,
        0.6690426468849182,
        0.3101179301738739,
        0.2347385436296463,
        0.405981183052063,
        0.32022932171821594,
        0.4602651000022888,
        0.44861045479774475,
        0.22756078839302063,
        0.46347784996032715,
        0.4591291844844818,
        0.17767974734306335,
        0.4432162046432495,
        0.6296087503433228,
        0.17158062756061554,
        0.27703624963760376,
        0.1828635334968567
    ],
    "val_loss_final": 1.519472241997719,
    "training_flops": 362276023440000.0,
    "total_eval_cost": 90569005860000.0,
    "early_stopping_step": null,
    "stopping_reason": "max_steps"
}